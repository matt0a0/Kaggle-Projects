{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f8eda51d-536a-44c5-b835-411afc4ab6d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bibliotecas Importadas\n"
     ]
    }
   ],
   "source": [
    "#Importando bibliotecas\n",
    "import tensorflow as tf\n",
    "from keras.datasets import mnist\n",
    "from tensorflow.keras import layers , models\n",
    "import numpy as np\n",
    "from keras.utils import to_categorical\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(\"Bibliotecas Importadas\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "63b35b40-c997-494a-abb2-9abf21ffbf11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregando o Dataset\n",
    "(x_train,y_train),(x_test,y_test)= mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "245c89f2-0173-47bc-875f-28279007a4fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Verificando o Formato da imagem 1 Layer, 60000 imagens formato de 28 x 28\n",
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f9e809fd-7e9f-4e69-8d6f-3d6e1fcaf26a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normalizando os pixels de cada imagem + Ajustando os elementos (Reshape) para as nossas redes neurais\n",
    "x_train = x_train.reshape((60000,28,28,1)).astype(\"float32\") / 255 #\n",
    "x_test = x_test.reshape((10000,28,28,1)).astype(\"float32\") / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "52810830-9332-40f9-a879-a7b75e0b0de4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28, 1)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "de950c8c-58d3-46bc-9583-be3a264a8d3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[0] #Agora é apenas uma label direta, uam forma boa de classificar seria usanto a to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6921f069-d478-4768-8696-6d09687e6dbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Como vamos usar Classentropy categorical, vamos deixar as labels de forma categórica\n",
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "29fbd95e-8f95-49e6-be0d-256be2e2bf32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_test[0]) # Vira um array de tamanho 10, onde o número classificado recebe o rótulo 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "85aeb876-763d-43fc-a4f6-051f5eaf694d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 1., 0., 0.], dtype=float32)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e89610be-a263-49ef-8792-2868d7260ca8",
   "metadata": {},
   "source": [
    "### Definindo uma cnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "91b0338e-4b6c-40d5-b32f-5e8551098383",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importando pois não quero usar o .layers pertencente ao sequencial\n",
    "from tensorflow.keras.models import Sequential \n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a63681ab-d28d-47c5-a381-84a72e7ed796",
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = models.Sequential()\n",
    "#Layer1\n",
    "model1.add(Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)))\n",
    "model1.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model1.add(Dropout(0.2))\n",
    "#Layer2\n",
    "model1.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model1.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model1.add(Dropout(0.2))\n",
    "#Adicionando o Flatten\n",
    "model1.add(Flatten())\n",
    "#Adicionando o Dense para classificar entre os 10 digitos\n",
    "model1.add(Dense(128, activation='relu'))\n",
    "model1.add(Dense(10,activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e8806d10-6892-42ce-a073-fb2a93ba917c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compilando a Cnn\n",
    "model1.compile(optimizer=\"ADAM\", loss=\"categorical_crossentropy\", metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3fc76daa-57a8-4f2e-844f-533920ceca11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_5 (Conv2D)           (None, 26, 26, 32)        320       \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 13, 13, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 13, 13, 32)        0         \n",
      "                                                                 \n",
      " conv2d_6 (Conv2D)           (None, 11, 11, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 5, 5, 64)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 5, 5, 64)          0         \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 1600)              0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 128)               204928    \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 10)                1290      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 225,034\n",
      "Trainable params: 225,034\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Treinando a CNN\n",
    "model1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "503ca051-e284-42f8-832d-63a5eb47257a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "469/469 [==============================] - 41s 85ms/step - loss: 0.2380 - accuracy: 0.9278 - val_loss: 0.0573 - val_accuracy: 0.9819\n",
      "Epoch 2/5\n",
      "469/469 [==============================] - 37s 78ms/step - loss: 0.0678 - accuracy: 0.9792 - val_loss: 0.0456 - val_accuracy: 0.9860\n",
      "Epoch 3/5\n",
      "469/469 [==============================] - 36s 77ms/step - loss: 0.0499 - accuracy: 0.9843 - val_loss: 0.0315 - val_accuracy: 0.9883\n",
      "Epoch 4/5\n",
      "469/469 [==============================] - 36s 77ms/step - loss: 0.0394 - accuracy: 0.9879 - val_loss: 0.0328 - val_accuracy: 0.9893\n",
      "Epoch 5/5\n",
      "469/469 [==============================] - 36s 77ms/step - loss: 0.0335 - accuracy: 0.9896 - val_loss: 0.0330 - val_accuracy: 0.9882\n"
     ]
    }
   ],
   "source": [
    "h1 = model1.fit(x_train,y_train , batch_size = 128, epochs = 5, verbose = 1, validation_data = (x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c8031f27-08d8-423e-a4f1-920afd916c18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 2s 6ms/step\n"
     ]
    }
   ],
   "source": [
    "cnn_predict = model1.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d99005a2-2e0d-47b7-b8a9-f7d9800227a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN Accuracy: 0.9882\n"
     ]
    }
   ],
   "source": [
    "cnn_accuracy = accuracy_score(np.argmax(y_test, axis=1), np.argmax(cnn_predict, axis=1))\n",
    "print(f\"CNN Accuracy: {cnn_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b17523ce-cfdd-47de-8d09-84604885cbfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Salvando o Modelo\n",
    "model1.save('saved_models/model1.hdf5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8edf4648-ea1f-498c-a334-736c2551e3da",
   "metadata": {},
   "source": [
    "### Definindo uma resnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0a11b9c8-5d99-484f-b2b5-0ed92b5ca692",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Criando o bloco Residual - Modelo Funcional\n",
    "def residual_block(x, filters, kernel_size=3, stride=1, conv_shortcut=True):\n",
    "    #Por padrão fazemos primeiro ajustes no output\n",
    "    y = layers.Conv2D(filters, kernel_size=kernel_size, strides=stride, padding='same')(x)\n",
    "    y = layers.BatchNormalization()(y)\n",
    "    y = layers.Activation('relu')(y)\n",
    "\n",
    "    y = layers.Conv2D(filters, kernel_size=kernel_size, padding='same')(y)\n",
    "    y = layers.BatchNormalization()(y)\n",
    "\n",
    "    if conv_shortcut:\n",
    "        x = layers.Conv2D(filters, kernel_size=1, strides=stride, padding='same')(x)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "\n",
    "    y = layers.Add()([x, y])\n",
    "    y = layers.Activation('relu')(y)\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ba8e2e70-146c-4ed1-ad6e-ca449ddd2e71",
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet_input = layers.Input(shape=(28, 28, 1))\n",
    "resnet_output = residual_block(resnet_input, filters=64)\n",
    "resnet_output = layers.GlobalAveragePooling2D()(resnet_output)\n",
    "resnet_output = layers.Dense(10, activation='softmax')(resnet_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c5f4e0ea-0d7a-434e-98d0-7923f9d787db",
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = models.Model(resnet_input, resnet_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "9afc2ba2-c3cb-4520-a274-b413eedc919d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_2 (InputLayer)           [(None, 28, 28, 1)]  0           []                               \n",
      "                                                                                                  \n",
      " conv2d_7 (Conv2D)              (None, 28, 28, 64)   640         ['input_2[0][0]']                \n",
      "                                                                                                  \n",
      " batch_normalization_3 (BatchNo  (None, 28, 28, 64)  256         ['conv2d_7[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_2 (Activation)      (None, 28, 28, 64)   0           ['batch_normalization_3[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_9 (Conv2D)              (None, 28, 28, 64)   128         ['input_2[0][0]']                \n",
      "                                                                                                  \n",
      " conv2d_8 (Conv2D)              (None, 28, 28, 64)   36928       ['activation_2[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_5 (BatchNo  (None, 28, 28, 64)  256         ['conv2d_9[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " batch_normalization_4 (BatchNo  (None, 28, 28, 64)  256         ['conv2d_8[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " add_1 (Add)                    (None, 28, 28, 64)   0           ['batch_normalization_5[0][0]',  \n",
      "                                                                  'batch_normalization_4[0][0]']  \n",
      "                                                                                                  \n",
      " activation_3 (Activation)      (None, 28, 28, 64)   0           ['add_1[0][0]']                  \n",
      "                                                                                                  \n",
      " global_average_pooling2d_1 (Gl  (None, 64)          0           ['activation_3[0][0]']           \n",
      " obalAveragePooling2D)                                                                            \n",
      "                                                                                                  \n",
      " dense_5 (Dense)                (None, 10)           650         ['global_average_pooling2d_1[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 39,114\n",
      "Trainable params: 38,730\n",
      "Non-trainable params: 384\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "4320a42d-d051-4ec8-bfda-77d492018b14",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compilando Resnet\n",
    "model2.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "2d118bfa-857d-429a-a2d2-94ffbeffaae3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1875/1875 [==============================] - 189s 100ms/step - loss: 1.2921 - accuracy: 0.6072 - val_loss: 7.1165 - val_accuracy: 0.1048\n",
      "Epoch 2/5\n",
      "1875/1875 [==============================] - 189s 101ms/step - loss: 0.7384 - accuracy: 0.7969 - val_loss: 10.2560 - val_accuracy: 0.2133\n",
      "Epoch 3/5\n",
      "1875/1875 [==============================] - 189s 101ms/step - loss: 0.5345 - accuracy: 0.8529 - val_loss: 9.2125 - val_accuracy: 0.2439\n",
      "Epoch 4/5\n",
      "1875/1875 [==============================] - 190s 102ms/step - loss: 0.4338 - accuracy: 0.8805 - val_loss: 5.8175 - val_accuracy: 0.3527\n",
      "Epoch 5/5\n",
      "1875/1875 [==============================] - 190s 101ms/step - loss: 0.3680 - accuracy: 0.8977 - val_loss: 11.6245 - val_accuracy: 0.2854\n"
     ]
    }
   ],
   "source": [
    "# Treinando o modelo\n",
    "h2 = model2.fit(x_train, y_train, epochs=5, validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "cec7367c-fe0a-417f-980b-b8cc5e3c1a6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 7s 22ms/step\n"
     ]
    }
   ],
   "source": [
    "resnet_predict = model2.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "663e3a60-278d-482b-9191-2f78c6d2f9c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resnet Accuracy: 0.2854\n"
     ]
    }
   ],
   "source": [
    "resnet_accuracy = accuracy_score(np.argmax(y_test, axis=-1), np.argmax(resnet_predict, axis=-1))\n",
    "print(f\"Resnet Accuracy: {resnet_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "dda08b8b-0b90-4f22-85d9-b1d8f3e26d0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Salvando o Modelo\n",
    "model1.save('saved_models/model2.hdf5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fb0ab4f-4d7b-43c9-98c4-85f1989cca07",
   "metadata": {},
   "source": [
    "### Definindo uma FCN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "adb6eb64-a3ab-4f4a-a654-1ac4b9998fa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model3 = models.Sequential() # Onde será feita a FCN Simples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "ce0a04ab-4ff3-40ee-bdae-bfdb055c054a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#FCN se diferencia pelo fato do mapa de saida ter as mesmas dimensões de um mapa de entrada\n",
    "model3.add(Flatten(input_shape=(28, 28, 1)))\n",
    "model3.add(Dense(128, activation='relu'))\n",
    "model3.add(Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "aabd0748-345c-43a4-a48d-cd0d699ef406",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2588 - accuracy: 0.9261 - val_loss: 0.1365 - val_accuracy: 0.9599\n",
      "Epoch 2/5\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.1126 - accuracy: 0.9668 - val_loss: 0.1022 - val_accuracy: 0.9679\n",
      "Epoch 3/5\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0779 - accuracy: 0.9766 - val_loss: 0.0812 - val_accuracy: 0.9740\n",
      "Epoch 4/5\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0577 - accuracy: 0.9825 - val_loss: 0.0977 - val_accuracy: 0.9715\n",
      "Epoch 5/5\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0460 - accuracy: 0.9857 - val_loss: 0.0702 - val_accuracy: 0.9777\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x24619b5e580>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model3.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model3.fit(x_train, y_train, epochs=5, validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "9f824883-cdf8-4411-89be-ad4413251925",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten_2 (Flatten)         (None, 784)               0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 128)               100480    \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 10)                1290      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 101,770\n",
      "Trainable params: 101,770\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "5539313a-67a6-4037-9d0c-7681c804d7a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 0s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "fcn_predict = model3.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "fa0b5b8d-8d69-457f-80bc-3ba7b0ee18e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FCN Accuracy: 0.9777\n"
     ]
    }
   ],
   "source": [
    "fcn_accuracy = accuracy_score(np.argmax(y_test, axis=1), np.argmax(fcn_predict, axis=1))\n",
    "print(f\"FCN Accuracy: {fcn_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "b382d9ec-2635-47d9-bb0b-073bd88f9fe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Salvando o Modelo\n",
    "model3.save('saved_models/model3.hdf5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff5eae3a-4455-49b9-96f3-c16794590e64",
   "metadata": {},
   "source": [
    "### Realizando Ensemble = AVG MODEL -> https://github.com/bnsreenu/python_for_microscopists/blob/master/213-ensemble_sign_language.py#L180"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "db23effe-f33d-4a99-8fc8-8d303586bd77",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "547ad699-8c18-4d3c-bac0-d27bf0f2b8a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregar os modelos treinados\n",
    "model1 = load_model('saved_models/model1.hdf5')\n",
    "model2 = load_model('saved_models/model2.hdf5')\n",
    "model3 = load_model('saved_models/model3.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "5942dd6b-add5-4e01-93a1-93481d00fa81",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [model1, model2, model3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "21ad6351-7183-446b-905b-177d736b446a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 2s 6ms/step\n",
      "313/313 [==============================] - 2s 6ms/step\n",
      "313/313 [==============================] - 0s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "# Fazer previsões usando cada modelo\n",
    "predictions = [model.predict(x_test) for model in models]\n",
    "predictions = np.array(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "e9a1aa52-5671-461f-ad3e-8234290592c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7, 2, 1, ..., 4, 5, 6], dtype=int64)"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Somar as previsões\n",
    "ensemble_prediction = np.argmax(np.sum(predictions, axis=0), axis=1)\n",
    "ensemble_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "301385f1-4b29-4771-88d9-4d9be80e09d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7, 2, 1, ..., 4, 5, 6], dtype=int64)"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_f = np.argmax(y_test, axis=1) # O que antes estava categórico voltou a ser multilabel\n",
    "y_test_f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "6a1f6639-779b-4474-99f4-e6241a435585",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy =  0.9891\n"
     ]
    }
   ],
   "source": [
    "ensemble_accuracy = accuracy_score(y_test_f, ensemble_prediction)\n",
    "\n",
    "print('Accuracy = ', ensemble_accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
